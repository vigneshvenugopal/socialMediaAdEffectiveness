---
title: "AppleWordCloud1"
author: "VokseDigital"
date: "March 16, 2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
#Setup the environment
library(SnowballC)
library(tm)
library(ggplot2)
library(RColorBrewer)
library(wordcloud)
library(topicmodels)
library(data.table)
library(stringi)
library(qdap)
library(dplyr)
library(rJava)
```
#####Read Twitter Data

```{r tweets}
#setwd("D:/OneDrive/Documents/Reference/Datasets")
tweets.df <- read.csv("D:/Learning/GreatLearning/Web_Social_Media_Analytics/Classroom/Twitter Text Mining Code/Data/tweets.csv")
```
#####Cleaning the text data by removing links, tags and delimiters.   
#####Build a Corpus, and specify the location to be the character Vectors  
```{r}
# Remove character string between < >
tweets.df$Tweet <- genX(tweets.df$Tweet, " <", ">")
head(tweets.df)

# Create document corpus with tweet text and clean up
myCorpus<- VCorpus(VectorSource(tweets.df$Tweet)) 

myCorpus <- tm_map(myCorpus,tolower)
mystopwords <- c((stopwords('SMART')),c("promoipodplayerpromo", "ipodplayerpromo", "pic", "http", "apple", "twitter", "hey", "https", "making"))
myCorpus <- tm_map(myCorpus,removeWords, mystopwords)
#myCorpus <- tm_map(myCorpus,removeNumbers)
myCorpus <- tm_map(myCorpus,removePunctuation)
myCorpus <- tm_map(myCorpus,stripWhitespace)
replaceWord <- function(corpus, oldword, newword)
{
  tm_map(corpus, content_transformer(gsub), pattern=oldword, replacement=newword)
  }
myCorpus <- replaceWord(myCorpus, "itunes", "itune")
myCorpus <- replaceWord(myCorpus, "itune", "itunes")
class(myCorpus)
```
#####Find the terms used most frequently
```{r Term frequency}
dtm1 <- TermDocumentMatrix(myCorpus, control= list(wordLengths= c(1, Inf)))

(freq.terms <- findFreqTerms(dtm1, lowfreq = 15))
term.freq <- rowSums(as.matrix(dtm1))
term.freq <- subset(term.freq, term.freq > 15)
df <- data.frame(term = names(term.freq), freq= term.freq)
```

#####plotting the graph of frequent terms
```{r Graph}
ggplot(df, aes(reorder(term, freq),freq)) + theme_bw() + geom_bar(stat = "identity")  + coord_flip() +labs(list(title="Term Frequency Chart", x="Terms", y="Term Counts")) 
```

#####plotting the word cloud
```{r Graph,echo=TRUE}
dtm <- DocumentTermMatrix(myCorpus)

m <- as.matrix(dtm)

v <- sort(colSums(m),decreasing=TRUE)

head(v,14)

words <- names(v)

d <- data.frame(word=words, freq=v)

wordcloud(d$word,d$freq,min.freq=15, random.order = F, colors = brewer.pal(8, "Dark2"), max.words = 100)
```

```{r Correlation}
# Identify and plot word correlations. For example - love
WordCorr <- apply_as_df(myCorpus, word_cor, word = "phone", r=.25)
plot(WordCorr)

qheat(vect2df(WordCorr[[1]], "word", "cor"), values=TRUE, high="red",
digits=2, order.by ="cor", plot = FALSE) + coord_flip()

# Messages with word - love
df <- data.frame(text=sapply(myCorpus, `[[`, "content"), stringsAsFactors=FALSE)
head(unique(df[grep("love", df$text), ]), n=10)

```

##### Find association with a specific keyword in the tweets - usopen, grandslam
```{r Find Association}
findAssocs(tdm, "usopen", 0.2)
findAssocs(tdm, "grandslam", 0.2)
```

##### Topic Modelling to identify latent/hidden topics using LDA technique
```{r Topic Modelling}
dtm <- as.DocumentTermMatrix(tdm)

rowTotals <- apply(dtm , 1, sum)

NullDocs <- dtm[rowTotals==0, ]
dtm   <- dtm[rowTotals> 0, ]

if (length(NullDocs$dimnames$Docs) > 0) {
tweets.df <- tweets.df[-as.numeric(NullDocs$dimnames$Docs),]
}

lda <- LDA(dtm, k = 5) # find 5 topic
term <- terms(lda, 7) # first 7 terms of every topic
(term <- apply(term, MARGIN = 2, paste, collapse = ", "))

topics<- topics(lda)
topics<- data.frame(date=(tweets.df$created), topic = topics)
qplot (date, ..count.., data=topics, geom ="density", fill= term[topic], position="stack")

```

#####Sentiment Analysis to identify positive/negative tweets
```{r Sentiment Analysis}
sentiments<- sentiment(tweets.df$text)
table(sentiments$polarity)
```

#####Sentiment Plot by date
```{r Sentiment Plot}
sentiments$score<- 0
sentiments$score[sentiments$polarity == "positive"]<-1
sentiments$score[sentiments$polarity == "negative"]<- -1
sentiments$date <- as.IDate(tweets.df$created)
result <- aggregate(score ~ date, data = sentiments, sum)
plot(result, type = "l")
```
##### Stream Graph for sentiment by date
```{r Stream Graph plotting}

Data<-sentiment(tweets.df$text)
Data$Date <- tweets.df$created
Data$text <- NULL
Data$Count <- 1
```

```{r}
graphdata <- aggregate(Count ~ polarity + as.character.Date(Date),data=Data,FUN=length)
colnames(graphdata)[2] <- "Date"
str(graphdata)
```
##### StreamGraph
```{r Type III,warning=FALSE, echo=FALSE}

graphdata %>%
streamgraph(polarity, Count, Date) %>%
  sg_axis_x(20) %>%
  sg_axis_x(1, "Date","%d-%b") %>%
  sg_legend(show=TRUE, label="Polarity: ")

```


